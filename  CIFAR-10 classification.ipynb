{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2GjIKWjj1s5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f63bef64-f6bd-4457-90f1-a548836182a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from os.path import join\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "!rm -rf ./logs/\n",
        "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import ResNet50\n",
        "import os\n",
        "import datetime\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Model\n",
        "from keras import datasets\n",
        "\n",
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/drscarlat/melanoma-resnet50-fine-tune/notebook"
      ],
      "metadata": {
        "id": "YDu4tFi_p3Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, Y_train), (x_test, Y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "ZPyDodlWIyVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a6b975-6426-4cfa-aade-877d3c1576c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train, Y_test = Y_train.flatten(), Y_test.flatten()\n",
        "\n",
        "X_train, Y_train = shuffle(x_train, Y_train, random_state=14)\n",
        "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
        "del X_train, Y_train\n",
        "print(\"shape of X_train\", x_train.shape)\n",
        "print(\"shape of y_train\", y_train.shape)\n",
        "print(\"shape of X_test\", x_val.shape)\n",
        "print(\"shape of y_test\", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bys6cCb2DK0L",
        "outputId": "0a2652b3-6f9c-4998-979e-dfc64ab5eead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of X_train (40000, 32, 32, 3)\n",
            "shape of y_train (40000,)\n",
            "shape of X_test (10000, 32, 32, 3)\n",
            "shape of y_test (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, Y_test))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(40000).batch(128)\n",
        "val_dataset = val_dataset.batch(128)\n",
        "del x_train, y_train, x_val, y_val"
      ],
      "metadata": {
        "id": "Yn21mTXXDRnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/drscarlat/melanoma-resnet50-fine-tune/notebook"
      ],
      "metadata": {
        "id": "CNo-LJLVa0mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "print(base.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOi4kaL7tNDu",
        "outputId": "e03f8899-0b32-49b0-dbdd-7a8828e3eb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = models.Sequential()\n",
        "teacher.add(layers.Lambda(lambda x: tf.image.resize(x,(224, 224))))\n",
        "teacher.add(base)\n",
        "teacher.add(layers.Flatten())\n",
        "# model.add(layers.Dropout(0.5))\n",
        "# model.add(layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "# model.add(layers.Dropout(0.5))\n",
        "teacher.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "dmYCXB7ftmx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the conv_base NOT trainable:\n",
        "\n",
        "for layer in base.layers[:]:\n",
        "   layer.trainable = False\n",
        "\n",
        "print('conv_base is now NOT trainable')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKZ5NRPKuCPp",
        "outputId": "baedf41a-e125-4829-8147-d2262a41f6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_base is now NOT trainable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ29qqPWvO_e",
        "outputId": "5e3ea2e9-4f06-43aa-92cb-3eb507b22536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 False\n",
            "1 conv1_pad False\n",
            "2 conv1_conv False\n",
            "3 conv1_bn False\n",
            "4 conv1_relu False\n",
            "5 pool1_pad False\n",
            "6 pool1_pool False\n",
            "7 conv2_block1_1_conv False\n",
            "8 conv2_block1_1_bn False\n",
            "9 conv2_block1_1_relu False\n",
            "10 conv2_block1_2_conv False\n",
            "11 conv2_block1_2_bn False\n",
            "12 conv2_block1_2_relu False\n",
            "13 conv2_block1_0_conv False\n",
            "14 conv2_block1_3_conv False\n",
            "15 conv2_block1_0_bn False\n",
            "16 conv2_block1_3_bn False\n",
            "17 conv2_block1_add False\n",
            "18 conv2_block1_out False\n",
            "19 conv2_block2_1_conv False\n",
            "20 conv2_block2_1_bn False\n",
            "21 conv2_block2_1_relu False\n",
            "22 conv2_block2_2_conv False\n",
            "23 conv2_block2_2_bn False\n",
            "24 conv2_block2_2_relu False\n",
            "25 conv2_block2_3_conv False\n",
            "26 conv2_block2_3_bn False\n",
            "27 conv2_block2_add False\n",
            "28 conv2_block2_out False\n",
            "29 conv2_block3_1_conv False\n",
            "30 conv2_block3_1_bn False\n",
            "31 conv2_block3_1_relu False\n",
            "32 conv2_block3_2_conv False\n",
            "33 conv2_block3_2_bn False\n",
            "34 conv2_block3_2_relu False\n",
            "35 conv2_block3_3_conv False\n",
            "36 conv2_block3_3_bn False\n",
            "37 conv2_block3_add False\n",
            "38 conv2_block3_out False\n",
            "39 conv3_block1_1_conv False\n",
            "40 conv3_block1_1_bn False\n",
            "41 conv3_block1_1_relu False\n",
            "42 conv3_block1_2_conv False\n",
            "43 conv3_block1_2_bn False\n",
            "44 conv3_block1_2_relu False\n",
            "45 conv3_block1_0_conv False\n",
            "46 conv3_block1_3_conv False\n",
            "47 conv3_block1_0_bn False\n",
            "48 conv3_block1_3_bn False\n",
            "49 conv3_block1_add False\n",
            "50 conv3_block1_out False\n",
            "51 conv3_block2_1_conv False\n",
            "52 conv3_block2_1_bn False\n",
            "53 conv3_block2_1_relu False\n",
            "54 conv3_block2_2_conv False\n",
            "55 conv3_block2_2_bn False\n",
            "56 conv3_block2_2_relu False\n",
            "57 conv3_block2_3_conv False\n",
            "58 conv3_block2_3_bn False\n",
            "59 conv3_block2_add False\n",
            "60 conv3_block2_out False\n",
            "61 conv3_block3_1_conv False\n",
            "62 conv3_block3_1_bn False\n",
            "63 conv3_block3_1_relu False\n",
            "64 conv3_block3_2_conv False\n",
            "65 conv3_block3_2_bn False\n",
            "66 conv3_block3_2_relu False\n",
            "67 conv3_block3_3_conv False\n",
            "68 conv3_block3_3_bn False\n",
            "69 conv3_block3_add False\n",
            "70 conv3_block3_out False\n",
            "71 conv3_block4_1_conv False\n",
            "72 conv3_block4_1_bn False\n",
            "73 conv3_block4_1_relu False\n",
            "74 conv3_block4_2_conv False\n",
            "75 conv3_block4_2_bn False\n",
            "76 conv3_block4_2_relu False\n",
            "77 conv3_block4_3_conv False\n",
            "78 conv3_block4_3_bn False\n",
            "79 conv3_block4_add False\n",
            "80 conv3_block4_out False\n",
            "81 conv4_block1_1_conv False\n",
            "82 conv4_block1_1_bn False\n",
            "83 conv4_block1_1_relu False\n",
            "84 conv4_block1_2_conv False\n",
            "85 conv4_block1_2_bn False\n",
            "86 conv4_block1_2_relu False\n",
            "87 conv4_block1_0_conv False\n",
            "88 conv4_block1_3_conv False\n",
            "89 conv4_block1_0_bn False\n",
            "90 conv4_block1_3_bn False\n",
            "91 conv4_block1_add False\n",
            "92 conv4_block1_out False\n",
            "93 conv4_block2_1_conv False\n",
            "94 conv4_block2_1_bn False\n",
            "95 conv4_block2_1_relu False\n",
            "96 conv4_block2_2_conv False\n",
            "97 conv4_block2_2_bn False\n",
            "98 conv4_block2_2_relu False\n",
            "99 conv4_block2_3_conv False\n",
            "100 conv4_block2_3_bn False\n",
            "101 conv4_block2_add False\n",
            "102 conv4_block2_out False\n",
            "103 conv4_block3_1_conv False\n",
            "104 conv4_block3_1_bn False\n",
            "105 conv4_block3_1_relu False\n",
            "106 conv4_block3_2_conv False\n",
            "107 conv4_block3_2_bn False\n",
            "108 conv4_block3_2_relu False\n",
            "109 conv4_block3_3_conv False\n",
            "110 conv4_block3_3_bn False\n",
            "111 conv4_block3_add False\n",
            "112 conv4_block3_out False\n",
            "113 conv4_block4_1_conv False\n",
            "114 conv4_block4_1_bn False\n",
            "115 conv4_block4_1_relu False\n",
            "116 conv4_block4_2_conv False\n",
            "117 conv4_block4_2_bn False\n",
            "118 conv4_block4_2_relu False\n",
            "119 conv4_block4_3_conv False\n",
            "120 conv4_block4_3_bn False\n",
            "121 conv4_block4_add False\n",
            "122 conv4_block4_out False\n",
            "123 conv4_block5_1_conv False\n",
            "124 conv4_block5_1_bn False\n",
            "125 conv4_block5_1_relu False\n",
            "126 conv4_block5_2_conv False\n",
            "127 conv4_block5_2_bn False\n",
            "128 conv4_block5_2_relu False\n",
            "129 conv4_block5_3_conv False\n",
            "130 conv4_block5_3_bn False\n",
            "131 conv4_block5_add False\n",
            "132 conv4_block5_out False\n",
            "133 conv4_block6_1_conv False\n",
            "134 conv4_block6_1_bn False\n",
            "135 conv4_block6_1_relu False\n",
            "136 conv4_block6_2_conv False\n",
            "137 conv4_block6_2_bn False\n",
            "138 conv4_block6_2_relu False\n",
            "139 conv4_block6_3_conv False\n",
            "140 conv4_block6_3_bn False\n",
            "141 conv4_block6_add False\n",
            "142 conv4_block6_out False\n",
            "143 conv5_block1_1_conv False\n",
            "144 conv5_block1_1_bn False\n",
            "145 conv5_block1_1_relu False\n",
            "146 conv5_block1_2_conv False\n",
            "147 conv5_block1_2_bn False\n",
            "148 conv5_block1_2_relu False\n",
            "149 conv5_block1_0_conv False\n",
            "150 conv5_block1_3_conv False\n",
            "151 conv5_block1_0_bn False\n",
            "152 conv5_block1_3_bn False\n",
            "153 conv5_block1_add False\n",
            "154 conv5_block1_out False\n",
            "155 conv5_block2_1_conv False\n",
            "156 conv5_block2_1_bn False\n",
            "157 conv5_block2_1_relu False\n",
            "158 conv5_block2_2_conv False\n",
            "159 conv5_block2_2_bn False\n",
            "160 conv5_block2_2_relu False\n",
            "161 conv5_block2_3_conv False\n",
            "162 conv5_block2_3_bn False\n",
            "163 conv5_block2_add False\n",
            "164 conv5_block2_out False\n",
            "165 conv5_block3_1_conv False\n",
            "166 conv5_block3_1_bn False\n",
            "167 conv5_block3_1_relu False\n",
            "168 conv5_block3_2_conv False\n",
            "169 conv5_block3_2_bn False\n",
            "170 conv5_block3_2_relu False\n",
            "171 conv5_block3_3_conv False\n",
            "172 conv5_block3_3_bn False\n",
            "173 conv5_block3_add False\n",
            "174 conv5_block3_out False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.compile(optimizer=optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"model compiled\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFNEOumYvaJ9",
        "outputId": "41b1db11-da25-405c-d916-a70adb3aea55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model compiled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "teacher.fit(x=train_dataset, epochs=10, validation_data=val_dataset, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knZf-P0vhZgP",
        "outputId": "a1ff667a-8a0d-4675-f4ed-f7d14f813a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 194s 580ms/step - loss: 3.3577 - accuracy: 0.7853 - val_loss: 3.4764 - val_accuracy: 0.7962\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 176s 564ms/step - loss: 1.1521 - accuracy: 0.9128 - val_loss: 3.0812 - val_accuracy: 0.8421\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 176s 563ms/step - loss: 0.6021 - accuracy: 0.9496 - val_loss: 3.3135 - val_accuracy: 0.8423\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 176s 564ms/step - loss: 0.4226 - accuracy: 0.9630 - val_loss: 4.1682 - val_accuracy: 0.8425\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 177s 565ms/step - loss: 0.3738 - accuracy: 0.9692 - val_loss: 3.7051 - val_accuracy: 0.8569\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 176s 564ms/step - loss: 0.3315 - accuracy: 0.9728 - val_loss: 4.8173 - val_accuracy: 0.8415\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 176s 562ms/step - loss: 0.3193 - accuracy: 0.9750 - val_loss: 5.9384 - val_accuracy: 0.8330\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 176s 564ms/step - loss: 0.3689 - accuracy: 0.9743 - val_loss: 5.3759 - val_accuracy: 0.8509\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 177s 566ms/step - loss: 0.3419 - accuracy: 0.9774 - val_loss: 5.3846 - val_accuracy: 0.8506\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 177s 565ms/step - loss: 0.2960 - accuracy: 0.9802 - val_loss: 5.5470 - val_accuracy: 0.8559\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35940b6fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No6KGaba0aBe",
        "outputId": "ef3f201d-8a3a-4db8-9e08-e18831b46e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lambda_4 (Lambda)           (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1003530   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,591,242\n",
            "Trainable params: 1,003,530\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ModelLoss, ModelAccuracy = teacher.evaluate(x_test, Y_test)\n",
        "print('Model Accuracy is {}'.format(ModelAccuracy))\n",
        "print('Model Loss is {}'.format(ModelLoss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQk1rgkg-ibG",
        "outputId": "7d90eb87-f9ae-4c55-fabd-fdaa8d94b9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 42s 107ms/step - loss: 5.9539 - accuracy: 0.8570\n",
            "Model Accuracy is 0.8569999933242798\n",
            "Model Loss is 5.95386266708374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "teacher evaluation:\n",
        "\n",
        "test accuracy: %85.7\n",
        "\n",
        "train accuracy: %98.02\n",
        "\n",
        "val accuracy: %85.59"
      ],
      "metadata": {
        "id": "_2EyKiN-tmOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.save('/content/drive/MyDrive/Colab_Notebook/Deep_Learning/hw3/teacher')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpopbSNiBpce",
        "outputId": "506820c9-a6d9-420c-e2ad-d0a954635466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab_Notebooks/Deep_Learning/hw3/teacher.zip\n",
            "  inflating: teacher/keras_metadata.pb  \n",
            "  inflating: teacher/saved_model.pb  \n",
            "   creating: teacher/assets/\n",
            "  inflating: teacher/variables/variables.index  \n",
            "  inflating: teacher/variables/variables.data-00000-of-00001  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/examples/vision/knowledge_distillation/\n",
        "\n",
        "https://www.kaggle.com/code/songrise/implementing-resnet-18-using-keras/notebook\n",
        "\n",
        "https://github.com/songrise/CNN_Keras/blob/main/src/ResNet-18.py"
      ],
      "metadata": {
        "id": "6XVZ0OHuYrdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetBlock(Model):\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0], kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1], kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "        if self.__down_sample:\n",
        "            self.res_conv = Conv2D(self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "hkEbbXiVjIjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2, padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "TYbPl6maVGQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "\n",
        "        x, y = data\n",
        "\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            student_predictions = self.student(x, training=True)\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "\n",
        "\n",
        "            distillation_loss = (\n",
        "                self.distillation_loss_fn(\n",
        "                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "                )\n",
        "                * self.temperature**2\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "        y_prediction = self.student(x, training=False)\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ],
      "metadata": {
        "id": "sJib-0gh06c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/hw3/teacher.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvV8cHzFREgD",
        "outputId": "5feb13f2-8be0-4141-f83a-849458f68e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab_Notebooks/Deep_Learning/hw3/teacher.zip\n",
            "  inflating: teacher/keras_metadata.pb  \n",
            "  inflating: teacher/saved_model.pb  \n",
            "   creating: teacher/assets/\n",
            "  inflating: teacher/variables/variables.index  \n",
            "  inflating: teacher/variables/variables.data-00000-of-00001  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = tf.keras.models.load_model('/content/teacher')\n",
        "\n",
        "student_base = ResNet18(10)\n",
        "student_base.build(input_shape = (None,224, 224, 3))\n",
        "student = models.Sequential()\n",
        "student.add(layers.Lambda(lambda x: tf.image.resize(x,(224, 224))))\n",
        "student.add(student_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrqI68GssH7E",
        "outputId": "66d7785e-c7c0-4666-ff0c-bf0dc177d085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7f5813090a30>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7f5813090a30>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype(\"float32\")\n",
        "X_train = np.reshape(X_train, (-1, 32, 32, 3))\n",
        "X_test = X_test.astype(\"float32\")\n",
        "X_test = np.reshape(X_test, (-1, 32, 32, 3))"
      ],
      "metadata": {
        "id": "1nmPEVsgkRWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Validation result for alpha and temperature** : epoch = 2\n",
        "\n",
        "alpha = [0.3, 0.5, 0.7, 0.8]\n",
        "\n",
        "temperature = [10, 13, 16, 18]\n"
      ],
      "metadata": {
        "id": "3SXPdSm0ykAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_split = 16\n",
        "iii = 0\n",
        "jjj = 0\n",
        "alpha = [0.3, 0.5, 0.7, 0.8]\n",
        "temperature = [10, 13, 16, 18]\n",
        "for train_index, test_index in KFold(n_split).split(Y_train):\n",
        "  x_train, x_test=X_train[train_index], X_train[test_index]\n",
        "  y_train,y_test=Y_train[train_index], Y_train[test_index]\n",
        "\n",
        "  distiller = Distiller(student=student, teacher=teacher)\n",
        "  distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=alpha[iii],\n",
        "    temperature=temperature[jjj])\n",
        "\n",
        "  print(alpha[iii], temperature[jjj])\n",
        "\n",
        "  distiller.fit(x_train, y_train, epochs=2)\n",
        "  if iii % 3 == 0 and iii!=0:\n",
        "    iii = -1\n",
        "    jjj += 1\n",
        "  iii += 1\n",
        "\n",
        "  ModelAccuracy, ModelLoss = distiller.evaluate(x_test, y_test)\n",
        "  print('\\nModel Loss is {}'.format(ModelLoss))\n",
        "  print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kerOD61e9U1N",
        "outputId": "3300f3fe-adee-4d13-856f-e573398ecc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3 10\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1465/1465 [==============================] - 314s 205ms/step - sparse_categorical_accuracy: 0.5311 - student_loss: 1.3105 - distillation_loss: 0.0312\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.7199 - student_loss: 0.8008 - distillation_loss: 0.0203\n",
            "98/98 [==============================] - 4s 40ms/step - sparse_categorical_accuracy: 0.6938 - student_loss: 0.8823\n",
            "\n",
            "Model Loss is 0.8487570881843567\n",
            "Model Accuracy is 0.6937599778175354\n",
            "0.5 10\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 315s 213ms/step - sparse_categorical_accuracy: 0.7760 - student_loss: 0.6418 - distillation_loss: 0.0167\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 311s 212ms/step - sparse_categorical_accuracy: 0.8248 - student_loss: 0.5015 - distillation_loss: 0.0137\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.7677 - student_loss: 0.6988\n",
            "\n",
            "Model Loss is 0.7113745808601379\n",
            "Model Accuracy is 0.7676799893379211\n",
            "0.7 10\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 311s 210ms/step - sparse_categorical_accuracy: 0.8565 - student_loss: 0.4138 - distillation_loss: 0.0119\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 311s 212ms/step - sparse_categorical_accuracy: 0.8884 - student_loss: 0.3197 - distillation_loss: 0.0100\n",
            "98/98 [==============================] - 4s 38ms/step - sparse_categorical_accuracy: 0.8400 - student_loss: 0.4682\n",
            "\n",
            "Model Loss is 0.45404067635536194\n",
            "Model Accuracy is 0.8399999737739563\n",
            "0.8 10\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9097 - student_loss: 0.2568 - distillation_loss: 0.0089\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9352 - student_loss: 0.1811 - distillation_loss: 0.0074\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.8394 - student_loss: 0.5544\n",
            "\n",
            "Model Loss is 0.13248617947101593\n",
            "Model Accuracy is 0.8393599987030029\n",
            "0.3 13\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 315s 212ms/step - sparse_categorical_accuracy: 0.9467 - student_loss: 0.1516 - distillation_loss: 0.0067\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 311s 213ms/step - sparse_categorical_accuracy: 0.9631 - student_loss: 0.1070 - distillation_loss: 0.0059\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9098 - student_loss: 0.2625\n",
            "\n",
            "Model Loss is 0.22280919551849365\n",
            "Model Accuracy is 0.9097599983215332\n",
            "0.5 13\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9647 - student_loss: 0.0990 - distillation_loss: 0.0057\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9724 - student_loss: 0.0763 - distillation_loss: 0.0053\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9376 - student_loss: 0.1933\n",
            "\n",
            "Model Loss is 0.13048599660396576\n",
            "Model Accuracy is 0.9376000165939331\n",
            "0.7 13\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 313s 210ms/step - sparse_categorical_accuracy: 0.9744 - student_loss: 0.0729 - distillation_loss: 0.0053\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 311s 213ms/step - sparse_categorical_accuracy: 0.9797 - student_loss: 0.0570 - distillation_loss: 0.0050\n",
            "98/98 [==============================] - 4s 38ms/step - sparse_categorical_accuracy: 0.9542 - student_loss: 0.1316\n",
            "\n",
            "Model Loss is 0.03905726224184036\n",
            "Model Accuracy is 0.9542400240898132\n",
            "0.8 13\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 315s 213ms/step - sparse_categorical_accuracy: 0.9795 - student_loss: 0.0585 - distillation_loss: 0.0051\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9826 - student_loss: 0.0504 - distillation_loss: 0.0048\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9558 - student_loss: 0.1313\n",
            "\n",
            "Model Loss is 0.011057557538151741\n",
            "Model Accuracy is 0.955839991569519\n",
            "0.3 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9824 - student_loss: 0.0522 - distillation_loss: 0.0048\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9875 - student_loss: 0.0368 - distillation_loss: 0.0045\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9651 - student_loss: 0.1017\n",
            "\n",
            "Model Loss is 0.11320044845342636\n",
            "Model Accuracy is 0.9651200175285339\n",
            "0.5 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9854 - student_loss: 0.0426 - distillation_loss: 0.0048\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9875 - student_loss: 0.0361 - distillation_loss: 0.0046\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9850 - student_loss: 0.0447\n",
            "\n",
            "Model Loss is 0.048935361206531525\n",
            "Model Accuracy is 0.9849600195884705\n",
            "0.7 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 313s 211ms/step - sparse_categorical_accuracy: 0.9866 - student_loss: 0.0375 - distillation_loss: 0.0046\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9898 - student_loss: 0.0309 - distillation_loss: 0.0045\n",
            "98/98 [==============================] - 4s 38ms/step - sparse_categorical_accuracy: 0.9600 - student_loss: 0.1231\n",
            "\n",
            "Model Loss is 0.1511480212211609\n",
            "Model Accuracy is 0.9599999785423279\n",
            "0.8 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9890 - student_loss: 0.0324 - distillation_loss: 0.0045\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9908 - student_loss: 0.0267 - distillation_loss: 0.0044\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9392 - student_loss: 0.1886\n",
            "\n",
            "Model Loss is 0.19836834073066711\n",
            "Model Accuracy is 0.9391999840736389\n",
            "0.3 18\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9891 - student_loss: 0.0314 - distillation_loss: 0.0045\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9919 - student_loss: 0.0251 - distillation_loss: 0.0043\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9610 - student_loss: 0.1352\n",
            "\n",
            "Model Loss is 0.03684317693114281\n",
            "Model Accuracy is 0.9609599709510803\n",
            "0.5 18\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9899 - student_loss: 0.0298 - distillation_loss: 0.0045\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9929 - student_loss: 0.0214 - distillation_loss: 0.0043\n",
            "98/98 [==============================] - 4s 38ms/step - sparse_categorical_accuracy: 0.9642 - student_loss: 0.1044\n",
            "\n",
            "Model Loss is 0.018668007105588913\n",
            "Model Accuracy is 0.9641600251197815\n",
            "0.7 18\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 315s 212ms/step - sparse_categorical_accuracy: 0.9911 - student_loss: 0.0255 - distillation_loss: 0.0044\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 312s 213ms/step - sparse_categorical_accuracy: 0.9930 - student_loss: 0.0206 - distillation_loss: 0.0043\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9885 - student_loss: 0.0384\n",
            "\n",
            "Model Loss is 0.0032949671149253845\n",
            "Model Accuracy is 0.9884799718856812\n",
            "0.8 18\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 316s 213ms/step - sparse_categorical_accuracy: 0.9929 - student_loss: 0.0224 - distillation_loss: 0.0043\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 311s 213ms/step - sparse_categorical_accuracy: 0.9921 - student_loss: 0.0225 - distillation_loss: 0.0044\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.9901 - student_loss: 0.0298\n",
            "\n",
            "Model Loss is 0.07706267386674881\n",
            "Model Accuracy is 0.9900799989700317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Validation result for alpha and temperature** : epoch = 2\n",
        "\n",
        "alpha = [0.3, 0.5, 0.7, 0.8]\n",
        "\n",
        "temperature = [10, 13, 16, 18]\n",
        "\n",
        "=============================================\n",
        "\n",
        "alpha, temperature = 0.3, 10\n",
        "\n",
        "      Model Loss is 0.8487570881843567\n",
        "      Model Accuracy is 0.6937599778175354\n",
        "\n",
        "alpha, temperature = 0.5, 10\n",
        "\n",
        "      Model Loss is 0.7113745808601379\n",
        "      Model Accuracy is 0.7676799893379211\n",
        "\n",
        "alpha, temperature = 0.7, 10\n",
        "\n",
        "      Model Loss is 0.45404067635536194\n",
        "      Model Accuracy is 0.8399999737739563\n",
        "\n",
        "alpha, temperature = 0.8, 10\n",
        "\n",
        "      Model Loss is 0.13248617947101593\n",
        "      Model Accuracy is 0.8393599987030029\n",
        "\n",
        "alpha, temperature = 0.3, 13\n",
        "\n",
        "      Model Loss is 0.22280919551849365\n",
        "\n",
        "      Model Accuracy is 0.9097599983215332\n",
        "\n",
        "alpha, temperature = 0.5, 13\n",
        "\n",
        "      Model Loss is 0.13048599660396576\n",
        "      Model Accuracy is 0.9376000165939331\n",
        "\n",
        "alpha, temperature = 0.7, 13\n",
        "\n",
        "      Model Loss is 0.03905726224184036\n",
        "      Model Accuracy is 0.9542400240898132\n",
        "\n",
        "alpha, temperature = 0.8, 13\n",
        "\n",
        "      Model Loss is 0.011057557538151741\n",
        "      Model Accuracy is 0.955839991569519\n",
        "\n",
        "alpha, temperature = 0.3, 16\n",
        "\n",
        "      Model Loss is 0.11320044845342636\n",
        "      Model Accuracy is 0.9651200175285339\n",
        "\n",
        "alpha, temperature = 0.5, 16\n",
        "\n",
        "      Model Loss is 0.048935361206531525\n",
        "      Model Accuracy is 0.9849600195884705\n",
        "\n",
        "alpha, temperature = 0.7, 16\n",
        "\n",
        "      Model Loss is 0.1511480212211609\n",
        "      Model Accuracy is 0.9599999785423279\n",
        "\n",
        "alpha, temperature = 0.8, 16\n",
        "      \n",
        "      Model Loss is 0.19836834073066711\n",
        "      Model Accuracy is 0.9391999840736389\n",
        "\n",
        "alpha, temperature = 0.3, 18\n",
        "\n",
        "      Model Loss is 0.03684317693114281\n",
        "      Model Accuracy is 0.9609599709510803\n",
        "\n",
        "alpha, temperature = 0.5, 18\n",
        "\n",
        "      Model Loss is 0.018668007105588913\n",
        "      Model Accuracy is 0.9641600251197815\n",
        "\n",
        "alpha, temperature = 0.7, 18\n",
        "\n",
        "      Model Loss is 0.0032949671149253845\n",
        "      Model Accuracy is 0.9884799718856812\n",
        "\n",
        "alpha, temperature = 0.8, 18\n",
        "      \n",
        "      Model Loss is 0.07706267386674881\n",
        "      Model Accuracy is 0.9900799989700317"
      ],
      "metadata": {
        "id": "oA4WOVgqqJbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation:\n",
        "\n",
        "alpha = [0.1, 0.3, 0.5, 0.7]\n",
        "\n",
        "temperature = [7, 10, 13, 16]"
      ],
      "metadata": {
        "id": "lqZbQWvc-g2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_split = 16\n",
        "iii = 0\n",
        "jjj = 0\n",
        "alpha = [0.1, 0.3, 0.5, 0.7]\n",
        "temperature = [7, 10, 13, 16]\n",
        "for train_index, test_index in KFold(n_split).split(Y_train):\n",
        "  x_train, x_test=X_train[train_index], X_train[test_index]\n",
        "  y_train,y_test=Y_train[train_index], Y_train[test_index]\n",
        "\n",
        "  distiller = Distiller(student=student, teacher=teacher)\n",
        "  distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=alpha[iii],\n",
        "    temperature=temperature[jjj])\n",
        "\n",
        "  print(alpha[iii], temperature[jjj])\n",
        "\n",
        "  distiller.fit(x_train, y_train, epochs=2)\n",
        "  if iii % 3 == 0 and iii!=0:\n",
        "    iii = -1\n",
        "    jjj += 1\n",
        "  iii += 1\n",
        "\n",
        "  ModelAccuracy, ModelLoss = distiller.evaluate(x_test, y_test)\n",
        "  print('\\nModel Loss is {}'.format(ModelLoss))\n",
        "  print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWEaI8uPnVBl",
        "outputId": "25ae9520-bf02-440e-ab93-f64e415c70a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 7\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 307s 207ms/step - sparse_categorical_accuracy: 0.5025 - student_loss: 1.3919 - distillation_loss: 0.0334\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 303s 207ms/step - sparse_categorical_accuracy: 0.7009 - student_loss: 0.8473 - distillation_loss: 0.0217\n",
            "98/98 [==============================] - 4s 36ms/step - sparse_categorical_accuracy: 0.7174 - student_loss: 0.7895\n",
            "\n",
            "Model Loss is 0.6231356859207153\n",
            "Model Accuracy is 0.7174400091171265\n",
            "0.3 7\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 309s 207ms/step - sparse_categorical_accuracy: 0.7682 - student_loss: 0.6689 - distillation_loss: 0.0176\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 303s 207ms/step - sparse_categorical_accuracy: 0.8204 - student_loss: 0.5193 - distillation_loss: 0.0143\n",
            "98/98 [==============================] - 4s 36ms/step - sparse_categorical_accuracy: 0.7491 - student_loss: 0.7461\n",
            "\n",
            "Model Loss is 0.6829172968864441\n",
            "Model Accuracy is 0.7491199970245361\n",
            "0.5 7\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 307s 207ms/step - sparse_categorical_accuracy: 0.8538 - student_loss: 0.4220 - distillation_loss: 0.0122\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 302s 206ms/step - sparse_categorical_accuracy: 0.8860 - student_loss: 0.3271 - distillation_loss: 0.0102\n",
            "98/98 [==============================] - 4s 36ms/step - sparse_categorical_accuracy: 0.8224 - student_loss: 0.5274\n",
            "\n",
            "Model Loss is 0.4101206064224243\n",
            "Model Accuracy is 0.8223999738693237\n",
            "0.7 7\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 307s 207ms/step - sparse_categorical_accuracy: 0.9100 - student_loss: 0.2584 - distillation_loss: 0.0089\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 303s 207ms/step - sparse_categorical_accuracy: 0.9349 - student_loss: 0.1826 - distillation_loss: 0.0075\n",
            "98/98 [==============================] - 4s 36ms/step - sparse_categorical_accuracy: 0.9088 - student_loss: 0.2736\n",
            "\n",
            "Model Loss is 0.18450286984443665\n",
            "Model Accuracy is 0.9088000059127808\n",
            "0.1 10\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 306s 206ms/step - sparse_categorical_accuracy: 0.9478 - student_loss: 0.1504 - distillation_loss: 0.0067\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 302s 206ms/step - sparse_categorical_accuracy: 0.9624 - student_loss: 0.1089 - distillation_loss: 0.0058\n",
            "98/98 [==============================] - 4s 36ms/step - sparse_categorical_accuracy: 0.9405 - student_loss: 0.1742\n",
            "\n",
            "Model Loss is 0.1238110288977623\n",
            "Model Accuracy is 0.9404799938201904\n",
            "0.3 10\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 306s 206ms/step - sparse_categorical_accuracy: 0.9661 - student_loss: 0.0990 - distillation_loss: 0.0056\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 302s 206ms/step - sparse_categorical_accuracy: 0.9741 - student_loss: 0.0765 - distillation_loss: 0.0053\n",
            "98/98 [==============================] - 4s 36ms/step - sparse_categorical_accuracy: 0.9283 - student_loss: 0.1978\n",
            "\n",
            "Model Loss is 0.027051378041505814\n",
            "Model Accuracy is 0.9283199906349182\n",
            "0.5 10\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 306s 207ms/step - sparse_categorical_accuracy: 0.9735 - student_loss: 0.0746 - distillation_loss: 0.0053\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 302s 206ms/step - sparse_categorical_accuracy: 0.9808 - student_loss: 0.0566 - distillation_loss: 0.0049\n",
            "98/98 [==============================] - 4s 36ms/step - sparse_categorical_accuracy: 0.9558 - student_loss: 0.1305\n",
            "\n",
            "Model Loss is 0.0952586755156517\n",
            "Model Accuracy is 0.955839991569519\n",
            "0.7 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_split = 16\n",
        "iii = 0\n",
        "jjj = 0\n",
        "alpha = [0.1, 0.3, 0.5, 0.7]\n",
        "temperature = [7, 10, 13, 16]\n",
        "for train_index, test_index in KFold(n_split).split(Y_train):\n",
        "  print(alpha[iii], temperature[jjj])\n",
        "  if temperature[jjj] in [7, 10]:\n",
        "    print(\"pass\")\n",
        "    if iii % 3 == 0 and iii!=0:\n",
        "      iii = -1\n",
        "      jjj += 1\n",
        "    iii += 1\n",
        "  else:\n",
        "    x_train, x_test=X_train[train_index], X_train[test_index]\n",
        "    y_train,y_test=Y_train[train_index], Y_train[test_index]\n",
        "\n",
        "    distiller = Distiller(student=student, teacher=teacher)\n",
        "    distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=alpha[iii],\n",
        "    temperature=temperature[jjj])\n",
        "    distiller.fit(x_train, y_train, epochs=2)\n",
        "    ModelAccuracy, ModelLoss = distiller.evaluate(x_test, y_test)\n",
        "    print('\\nModel Loss is {}'.format(ModelLoss))\n",
        "    print('Model Accuracy is {}'.format(ModelAccuracy))\n",
        "    if iii % 3 == 0 and iii!=0:\n",
        "      iii = -1\n",
        "      jjj += 1\n",
        "    iii += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyWfn1I-7Jc1",
        "outputId": "932ca311-116c-4af5-d66e-c45000c20021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 7\n",
            "pass\n",
            "0.3 7\n",
            "pass\n",
            "0.5 7\n",
            "pass\n",
            "0.7 7\n",
            "pass\n",
            "0.1 10\n",
            "pass\n",
            "0.3 10\n",
            "pass\n",
            "0.5 10\n",
            "pass\n",
            "0.7 10\n",
            "pass\n",
            "0.1 13\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1465/1465 [==============================] - 307s 200ms/step - sparse_categorical_accuracy: 0.5064 - student_loss: 1.3741 - distillation_loss: 0.0321\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 298s 203ms/step - sparse_categorical_accuracy: 0.7004 - student_loss: 0.8541 - distillation_loss: 0.0212\n",
            "98/98 [==============================] - 4s 37ms/step - sparse_categorical_accuracy: 0.5549 - student_loss: 1.3738\n",
            "\n",
            "Model Loss is 0.6897273659706116\n",
            "Model Accuracy is 0.5548800230026245\n",
            "0.3 13\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 302s 204ms/step - sparse_categorical_accuracy: 0.7700 - student_loss: 0.6661 - distillation_loss: 0.0170\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 299s 204ms/step - sparse_categorical_accuracy: 0.8212 - student_loss: 0.5185 - distillation_loss: 0.0139\n",
            "98/98 [==============================] - 4s 34ms/step - sparse_categorical_accuracy: 0.8058 - student_loss: 0.5568\n",
            "\n",
            "Model Loss is 0.30154141783714294\n",
            "Model Accuracy is 0.8057600259780884\n",
            "0.5 13\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 301s 203ms/step - sparse_categorical_accuracy: 0.8507 - student_loss: 0.4297 - distillation_loss: 0.0120\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 299s 204ms/step - sparse_categorical_accuracy: 0.8837 - student_loss: 0.3345 - distillation_loss: 0.0102\n",
            "98/98 [==============================] - 4s 34ms/step - sparse_categorical_accuracy: 0.8138 - student_loss: 0.5369\n",
            "\n",
            "Model Loss is 0.3543245494365692\n",
            "Model Accuracy is 0.813759982585907\n",
            "0.7 13\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 302s 204ms/step - sparse_categorical_accuracy: 0.9033 - student_loss: 0.2735 - distillation_loss: 0.0090\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 299s 204ms/step - sparse_categorical_accuracy: 0.9311 - student_loss: 0.1961 - distillation_loss: 0.0075\n",
            "98/98 [==============================] - 4s 34ms/step - sparse_categorical_accuracy: 0.8755 - student_loss: 0.3563\n",
            "\n",
            "Model Loss is 0.22532203793525696\n",
            "Model Accuracy is 0.8755199909210205\n",
            "0.1 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 300s 203ms/step - sparse_categorical_accuracy: 0.9445 - student_loss: 0.1578 - distillation_loss: 0.0067\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 299s 204ms/step - sparse_categorical_accuracy: 0.9587 - student_loss: 0.1157 - distillation_loss: 0.0059\n",
            "98/98 [==============================] - 4s 34ms/step - sparse_categorical_accuracy: 0.9197 - student_loss: 0.2429\n",
            "\n",
            "Model Loss is 0.19593480229377747\n",
            "Model Accuracy is 0.9196799993515015\n",
            "0.3 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 301s 203ms/step - sparse_categorical_accuracy: 0.9635 - student_loss: 0.1056 - distillation_loss: 0.0057\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 300s 204ms/step - sparse_categorical_accuracy: 0.9715 - student_loss: 0.0812 - distillation_loss: 0.0053\n",
            "98/98 [==============================] - 4s 34ms/step - sparse_categorical_accuracy: 0.9510 - student_loss: 0.1327\n",
            "\n",
            "Model Loss is 0.12011982500553131\n",
            "Model Accuracy is 0.9510400295257568\n",
            "0.5 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 305s 205ms/step - sparse_categorical_accuracy: 0.9724 - student_loss: 0.0787 - distillation_loss: 0.0054\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 301s 206ms/step - sparse_categorical_accuracy: 0.9788 - student_loss: 0.0585 - distillation_loss: 0.0049\n",
            "98/98 [==============================] - 4s 34ms/step - sparse_categorical_accuracy: 0.9667 - student_loss: 0.0924\n",
            "\n",
            "Model Loss is 0.04457022622227669\n",
            "Model Accuracy is 0.9667199850082397\n",
            "0.7 16\n",
            "Epoch 1/2\n",
            "1465/1465 [==============================] - 307s 205ms/step - sparse_categorical_accuracy: 0.9793 - student_loss: 0.0589 - distillation_loss: 0.0050\n",
            "Epoch 2/2\n",
            "1465/1465 [==============================] - 300s 205ms/step - sparse_categorical_accuracy: 0.9826 - student_loss: 0.0500 - distillation_loss: 0.0049\n",
            "98/98 [==============================] - 4s 34ms/step - sparse_categorical_accuracy: 0.9750 - student_loss: 0.0805\n",
            "\n",
            "Model Loss is 0.01704961620271206\n",
            "Model Accuracy is 0.9750400185585022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Validation result for alpha and temperature** : epoch = 2\n",
        "\n",
        "alpha, temperature = 0.1, 7\n",
        "\n",
        "        Model Loss is 0.6231356859207153\n",
        "\n",
        "        Model Accuracy is 0.7174400091171265\n",
        "\n",
        "alpha, temperature = 0.3, 7\n",
        "\n",
        "        Model Loss is 0.6829172968864441\n",
        "  \n",
        "        Model Accuracy is 0.7491199970245361\n",
        "\n",
        "alpha, temperature = 0.5, 7\n",
        "\n",
        "        Model Loss is 0.4101206064224243\n",
        "  \n",
        "        Model Accuracy is 0.8223999738693237\n",
        "\n",
        "alpha, temperature = 0.7, 7\n",
        "\n",
        "        Model Loss is 0.18450286984443665\n",
        "      \n",
        "        Model Accuracy is 0.9088000059127808\n",
        "\n",
        "alpha, temperature = 0.1, 10\n",
        "\n",
        "        Model Loss is 0.1238110288977623\n",
        "      \n",
        "        Model Accuracy is 0.9404799938201904\n",
        "\n",
        "alpha, temperature = 0.3, 10\n",
        "\n",
        "        Model Loss is 0.027051378041505814\n",
        "      \n",
        "        Model Accuracy is 0.9283199906349182\n",
        "\n",
        "alpha, temperature = 0.5, 10\n",
        "\n",
        "        Model Loss is 0.0952586755156517\n",
        "      \n",
        "        Model Accuracy is 0.955839991569519\n",
        "\n",
        "alpha, temperature = 0.7, 10\n",
        "\n",
        "        Model Accuracy is 0.9136000275611877\n",
        "        \n",
        "        Model Loss is 0.3140583336353302\n",
        "\n",
        "alpha, temperature = 0.1, 13\n",
        "\n",
        "        Model Loss is 0.6897273659706116\n",
        "  \n",
        "        Model Accuracy is 0.5548800230026245\n",
        "\n",
        "alpha, temperature = 0.3, 13\n",
        "\n",
        "        Model Loss is 0.30154141783714294\n",
        "        Model Accuracy is 0.8057600259780884\n",
        "\n",
        "alpha, temperature = 0.5, 13\n",
        "\n",
        "        Model Loss is 0.3543245494365692\n",
        "      \n",
        "        Model Accuracy is 0.813759982585907\n",
        "\n",
        "alpha, temperature = 0.7, 13\n",
        "\n",
        "        Model Loss is 0.22532203793525696\n",
        "        \n",
        "        Model Accuracy is 0.8755199909210205\n",
        "\n",
        "alpha, temperature = 0.1, 16\n",
        "\n",
        "        Model Loss is 0.19593480229377747\n",
        "        \n",
        "        Model Accuracy is 0.9196799993515015\n",
        "\n",
        "alpha, temperature = 0.3, 16\n",
        "\n",
        "        Model Loss is 0.12011982500553131\n",
        "      \n",
        "        Model Accuracy is 0.9510400295257568\n",
        "\n",
        "alpha, temperature = 0.5, 16\n",
        "\n",
        "        Model Loss is 0.04457022622227669\n",
        "      \n",
        "        Model Accuracy is 0.9667199850082397\n",
        "\n",
        "alpha, temperature = 0.7, 16\n",
        "\n",
        "        Model Loss is 0.01704961620271206\n",
        "        \n",
        "        Model Accuracy is 0.9750400185585022"
      ],
      "metadata": {
        "id": "j5QsRJK_qNcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================================\n",
        "\n",
        "best parameter:\n",
        "\n",
        "alpha = 0.8\n",
        "\n",
        "temperature = 18\n",
        "\n",
        "\n",
        "Loss : 0.07706267386674881\n",
        "\n",
        "Accuracy : 0.9900799989700317\n",
        "\n",
        "===================================================="
      ],
      "metadata": {
        "id": "Y-E_flBJTD_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training : alpha = 0.8 ,temperature = 18"
      ],
      "metadata": {
        "id": "GJMqzL-Us6bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distill teacher to student\n",
        "\n",
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student, teacher=teacher)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.8,\n",
        "    temperature=18,\n",
        ")"
      ],
      "metadata": {
        "id": "6VH7kwFx4S-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distill teacher to student\n",
        "distiller.fit(X_train, Y_train, epochs=11)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvLEtyFDiKPX",
        "outputId": "cad6cd78-ed96-415e-8b81-1a394a76e378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 328s 202ms/step - sparse_categorical_accuracy: 0.5028 - student_loss: 1.3780 - distillation_loss: 0.0318\n",
            "Epoch 2/11\n",
            "1563/1563 [==============================] - 313s 200ms/step - sparse_categorical_accuracy: 0.7087 - student_loss: 0.8259 - distillation_loss: 0.0205\n",
            "Epoch 3/11\n",
            "1563/1563 [==============================] - 313s 200ms/step - sparse_categorical_accuracy: 0.7827 - student_loss: 0.6249 - distillation_loss: 0.0160\n",
            "Epoch 4/11\n",
            "1563/1563 [==============================] - 313s 200ms/step - sparse_categorical_accuracy: 0.8271 - student_loss: 0.4962 - distillation_loss: 0.0133\n",
            "Epoch 5/11\n",
            "1563/1563 [==============================] - 313s 201ms/step - sparse_categorical_accuracy: 0.8590 - student_loss: 0.4048 - distillation_loss: 0.0114\n",
            "Epoch 6/11\n",
            "1563/1563 [==============================] - 314s 201ms/step - sparse_categorical_accuracy: 0.8898 - student_loss: 0.3137 - distillation_loss: 0.0098\n",
            "Epoch 7/11\n",
            "1563/1563 [==============================] - 313s 200ms/step - sparse_categorical_accuracy: 0.9179 - student_loss: 0.2346 - distillation_loss: 0.0082\n",
            "Epoch 8/11\n",
            "1563/1563 [==============================] - 314s 201ms/step - sparse_categorical_accuracy: 0.9402 - student_loss: 0.1701 - distillation_loss: 0.0070\n",
            "Epoch 9/11\n",
            "1563/1563 [==============================] - 313s 200ms/step - sparse_categorical_accuracy: 0.9563 - student_loss: 0.1243 - distillation_loss: 0.0061\n",
            "Epoch 10/11\n",
            "1563/1563 [==============================] - 314s 201ms/step - sparse_categorical_accuracy: 0.9656 - student_loss: 0.0960 - distillation_loss: 0.0057\n",
            "Epoch 11/11\n",
            "1563/1563 [==============================] - 313s 200ms/step - sparse_categorical_accuracy: 0.9717 - student_loss: 0.0832 - distillation_loss: 0.0055\n",
            "313/313 [==============================] - 11s 34ms/step - sparse_categorical_accuracy: 0.8395 - student_loss: 0.6280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8395000100135803, 0.8694968819618225]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "alpha = 0.8\n",
        "\n",
        "temperature = 18\n",
        "\n",
        "test accuracy:\n",
        "\n",
        "      0.8395000100135803\n",
        "\n",
        "test loss:\n",
        "\n",
        "      0.8694968819618225"
      ],
      "metadata": {
        "id": "KPk_fNswXVY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "rKA0B0deFbEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data.\n",
        "x_train = x_train.astype('float32')\n",
        "X_test = x_test.astype('float32')\n",
        "x_train /= 255.0\n",
        "X_test /= 255.0"
      ],
      "metadata": {
        "id": "tZsw17TIFhkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2,shuffle = True)\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"Y_train: \", y_train.shape)\n",
        "print(\"\\nX_test: \", X_test.shape)\n",
        "print(\"Y_test: \", y_test.shape)\n",
        "print(\"\\nX_val: \", X_val.shape)\n",
        "print(\"Y_val: \", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGF6XXLLFneG",
        "outputId": "a9f99035-f9f2-41cf-8f46-b67cadf9397c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (40000, 32, 32, 3)\n",
            "Y_train:  (40000, 1)\n",
            "\n",
            "X_test:  (10000, 32, 32, 3)\n",
            "Y_test:  (10000, 1)\n",
            "\n",
            "X_val:  (10000, 32, 32, 3)\n",
            "Y_val:  (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder()\n",
        "encoder.fit(y_train)\n",
        "Y_train = encoder.transform(y_train).toarray()\n",
        "Y_test = encoder.transform(y_test).toarray()\n",
        "Y_val =  encoder.transform(y_val).toarray()"
      ],
      "metadata": {
        "id": "yOu13meCFtOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(60000).batch(128)\n",
        "val_dataset = val_dataset.batch(128)\n",
        "# del X_train, Y_train, X_val, Y_val, X_test, Y_test, x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "G1EqMYjixfRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# aug = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.05,\n",
        "#                              height_shift_range=0.05)\n",
        "# aug.fit(X_train)"
      ],
      "metadata": {
        "id": "hciqdjjvF0dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_base = ResNet18(10)\n",
        "student_base.build(input_shape = (None,224, 224, 3))\n",
        "student = models.Sequential()\n",
        "student.add(layers.Lambda(lambda x: tf.image.resize(x,(224, 224))))\n",
        "student.add(student_base)\n",
        "student.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "re1iZpf4Gqgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0eac7d-855b-4296-deca-9767000a4e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7fad40404be0>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7fad40404be0>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=7, mode='auto',min_delta=0.002, restore_best_weights=True)\n",
        "\n",
        "history = student.fit(x=train_dataset,\n",
        "          epochs=100,\n",
        "          validation_data=val_dataset,\n",
        "          callbacks=[callback])"
      ],
      "metadata": {
        "id": "I6TAiu8DXHb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122b7074-bf29-4f86-9474-3b5eb228463f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 146s 423ms/step - loss: 1.4045 - accuracy: 0.5008 - val_loss: 1.9576 - val_accuracy: 0.3978\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 131s 418ms/step - loss: 0.8662 - accuracy: 0.6938 - val_loss: 1.5954 - val_accuracy: 0.4783\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 131s 417ms/step - loss: 0.6450 - accuracy: 0.7731 - val_loss: 1.8131 - val_accuracy: 0.5348\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.5109 - accuracy: 0.8209 - val_loss: 2.0435 - val_accuracy: 0.5652\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 131s 418ms/step - loss: 0.4157 - accuracy: 0.8550 - val_loss: 1.4214 - val_accuracy: 0.6509\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 131s 418ms/step - loss: 0.3277 - accuracy: 0.8854 - val_loss: 1.0105 - val_accuracy: 0.7010\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.2529 - accuracy: 0.9102 - val_loss: 2.4103 - val_accuracy: 0.5330\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 131s 417ms/step - loss: 0.1922 - accuracy: 0.9319 - val_loss: 0.8077 - val_accuracy: 0.7726\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.1380 - accuracy: 0.9507 - val_loss: 1.1016 - val_accuracy: 0.7409\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.1064 - accuracy: 0.9637 - val_loss: 1.0951 - val_accuracy: 0.7507\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 131s 417ms/step - loss: 0.0832 - accuracy: 0.9709 - val_loss: 1.3777 - val_accuracy: 0.7077\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 130s 417ms/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 1.5199 - val_accuracy: 0.7065\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0607 - accuracy: 0.9788 - val_loss: 1.6012 - val_accuracy: 0.7192\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0757 - accuracy: 0.9733 - val_loss: 1.8670 - val_accuracy: 0.6864\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 1.0735 - val_accuracy: 0.7749\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 131s 417ms/step - loss: 0.0399 - accuracy: 0.9864 - val_loss: 0.8842 - val_accuracy: 0.8090\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 1.1397 - val_accuracy: 0.7802\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0519 - accuracy: 0.9823 - val_loss: 1.7169 - val_accuracy: 0.7277\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 131s 417ms/step - loss: 0.0416 - accuracy: 0.9858 - val_loss: 0.8261 - val_accuracy: 0.8245\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 1.4745 - val_accuracy: 0.7512\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0316 - accuracy: 0.9888 - val_loss: 1.4486 - val_accuracy: 0.7485\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 131s 417ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 2.0182 - val_accuracy: 0.7062\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0278 - accuracy: 0.9901 - val_loss: 1.7462 - val_accuracy: 0.7447\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 1.6360 - val_accuracy: 0.7219\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 131s 417ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 1.6676 - val_accuracy: 0.7426\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 130s 416ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 1.3742 - val_accuracy: 0.7728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ModelLoss, ModelAccuracy = student.evaluate(X_train, Y_train)\n",
        "\n",
        "print('Model Loss is {}'.format(ModelLoss))\n",
        "print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKCsSMbshGcM",
        "outputId": "b546e539-7981-4996-9785-bb17c80b7aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 41s 32ms/step - loss: 0.0422 - accuracy: 0.9854\n",
            "Model Loss is 0.04221908748149872\n",
            "Model Accuracy is 0.9854000210762024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ModelLoss, ModelAccuracy = student.evaluate(X_test, Y_test)\n",
        "\n",
        "print('Model Loss is {}'.format(ModelLoss))\n",
        "print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJtQ-PxghLxb",
        "outputId": "f75c94e0-8ac5-4bbf-8ea7-1402500d555a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 11s 33ms/step - loss: 0.8673 - accuracy: 0.8227\n",
            "Model Loss is 0.8673175573348999\n",
            "Model Accuracy is 0.822700023651123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result:\n",
        "\n",
        "      train Loss : 0.04221908748149872\n",
        "\n",
        "      train Accuracy : 0.9854000210762024\n",
        "\n",
        "      test Loss : 0.8673175573348999\n",
        "\n",
        "      test Accuracy : 0.822700023651123"
      ],
      "metadata": {
        "id": "O0zQCTpajdr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotmodelhistory(history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy'])\n",
        "    axs[0].plot(history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss'])\n",
        "    axs[1].plot(history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "plotmodelhistory(history)"
      ],
      "metadata": {
        "id": "fyZxSwbgGxMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "66324746-c98e-45b2-f265-6aa64466156e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with distilation algorithm:\n",
        "\n",
        "      test accuracy : 0.84\n",
        "\n",
        "      test loss : 0.87\n",
        "\n",
        "\n",
        "without distilation algorithm(ResNet18):\n",
        "    \n",
        "      test Loss : 0.87\n",
        "\n",
        "      test Accuracy : 0.823"
      ],
      "metadata": {
        "id": "y4EMqiiFYGiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "مطابق توضیحاتی که در وب سایت معرفی شده در دستورکار وجود دارد در حالتی که مدل از صفر بر روی دیتای آموزشی ترین شود به دقت پایین تری میرسیم. در قسمت قبل از الگوریتم گفته شده استفاده شد و به این صورت بود که دو تابع هزینه بین خروجی مدل با لیبل های واقعی و تابع هزینه بین مدل و خروجی های مدل معلم در نظر گرفته شد. این کار باعث شد تا از یادگیری‌ای که پیش از این بر روی مدل معلم صورت گرفته شده بود استفاده شود و به نوعی این اطلاعات به مدل کوچکتر منتقل شود.\n",
        "به عبارت دیگر در حالتی که ما از لیبل های هارد استفاده کنیم و مدل به دنبال یادگیری آنها باشد پروسه آموزش ضعیف تر از حالتی است که ما با لیبل‌های نرم (که در مدلی با دقت خوب به دست آمده‌اند) عمل میکنیم"
      ],
      "metadata": {
        "id": "IxgUhQ2GmUvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT MODULES\n",
        "import sys\n",
        "from os.path import join\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "!rm -rf ./logs/\n",
        "%load_ext tensorboard\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#from tensorflow.python.keras.applications import ResNet50\n",
        "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import ResNet50\n",
        "from google.colab import drive\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLs6-uOTFLJo",
        "outputId": "689d65e2-1afe-410e-e7b9-460ffffb96ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = ResNet50(weights = None, include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "print(base.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phpS4FgmFLmr",
        "outputId": "56767807-5bfb-4b66-edad-7312d926f65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Lambda(lambda x: tf.image.resize(x,(224, 224))))\n",
        "model.add(base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "CibCxJooFzVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"model compiled\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl2GRMvLGH1M",
        "outputId": "6e6b6721-224f-47fa-e83d-7e3668c07c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model compiled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### batch = 64\n",
        "\n",
        "# Load in the data\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "# Distribute it to train and test set\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "# flatten the label values\n",
        "Y_train, Y_test = Y_train.flatten(), Y_test.flatten()\n",
        "\n",
        "X_train, Y_train = shuffle(X_train, Y_train, random_state=14)\n",
        "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
        "# del X_train, Y_train\n",
        "print(\"shape of X_train\", x_train.shape)\n",
        "print(\"shape of y_train\", y_train.shape)\n",
        "print(\"shape of X_test\", x_val.shape)\n",
        "print(\"shape of y_test\", y_val.shape)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(60000).batch(64)\n",
        "val_dataset = val_dataset.batch(64)\n",
        "# del x_train, y_train, x_val, y_val, X_test, Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr-6mnbblfn0",
        "outputId": "a09d769b-08c7-403c-b03b-6d53bde09d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "shape of X_train (40000, 32, 32, 3)\n",
            "shape of y_train (40000,)\n",
            "shape of X_test (10000, 32, 32, 3)\n",
            "shape of y_test (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=7, mode='auto',min_delta=0.005, restore_best_weights=True)\n",
        "\n",
        "model.fit(x=train_dataset,\n",
        "          epochs=50,\n",
        "          validation_data=val_dataset,\n",
        "          callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_HONdxMlq0y",
        "outputId": "a4298729-3ee2-4421-9f18-4614687b6bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "625/625 [==============================] - 434s 660ms/step - loss: 3.6616 - accuracy: 0.3381 - val_loss: 1.6491 - val_accuracy: 0.4253\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - 412s 660ms/step - loss: 1.5248 - accuracy: 0.4911 - val_loss: 1.3719 - val_accuracy: 0.5349\n",
            "Epoch 3/50\n",
            "625/625 [==============================] - 412s 659ms/step - loss: 1.1701 - accuracy: 0.5940 - val_loss: 1.1575 - val_accuracy: 0.5950\n",
            "Epoch 4/50\n",
            "625/625 [==============================] - 412s 659ms/step - loss: 0.9816 - accuracy: 0.6610 - val_loss: 1.6783 - val_accuracy: 0.6292\n",
            "Epoch 5/50\n",
            "625/625 [==============================] - 412s 660ms/step - loss: 0.8267 - accuracy: 0.7138 - val_loss: 1.1120 - val_accuracy: 0.6679\n",
            "Epoch 6/50\n",
            "625/625 [==============================] - 413s 660ms/step - loss: 0.7195 - accuracy: 0.7530 - val_loss: 0.9293 - val_accuracy: 0.7205\n",
            "Epoch 7/50\n",
            "625/625 [==============================] - 413s 660ms/step - loss: 0.6117 - accuracy: 0.7959 - val_loss: 0.9180 - val_accuracy: 0.7019\n",
            "Epoch 8/50\n",
            "625/625 [==============================] - 412s 659ms/step - loss: 0.4878 - accuracy: 0.8318 - val_loss: 0.7572 - val_accuracy: 0.7501\n",
            "Epoch 9/50\n",
            "625/625 [==============================] - 413s 660ms/step - loss: 0.4277 - accuracy: 0.8548 - val_loss: 0.9792 - val_accuracy: 0.6931\n",
            "Epoch 10/50\n",
            "625/625 [==============================] - 413s 660ms/step - loss: 0.3374 - accuracy: 0.8857 - val_loss: 2.1973 - val_accuracy: 0.7045\n",
            "Epoch 11/50\n",
            "625/625 [==============================] - 410s 656ms/step - loss: 0.2464 - accuracy: 0.9168 - val_loss: 0.8576 - val_accuracy: 0.7637\n",
            "Epoch 12/50\n",
            "625/625 [==============================] - 406s 649ms/step - loss: 0.1833 - accuracy: 0.9371 - val_loss: 1.4344 - val_accuracy: 0.6995\n",
            "Epoch 13/50\n",
            "625/625 [==============================] - 410s 657ms/step - loss: 0.1865 - accuracy: 0.9365 - val_loss: 1.7338 - val_accuracy: 0.6935\n",
            "Epoch 14/50\n",
            "625/625 [==============================] - 412s 659ms/step - loss: 0.1364 - accuracy: 0.9546 - val_loss: 1.6667 - val_accuracy: 0.7309\n",
            "Epoch 15/50\n",
            "625/625 [==============================] - 412s 659ms/step - loss: 0.1429 - accuracy: 0.9538 - val_loss: 1.2007 - val_accuracy: 0.7470\n",
            "Epoch 16/50\n",
            "625/625 [==============================] - 412s 659ms/step - loss: 0.1030 - accuracy: 0.9650 - val_loss: 1.1116 - val_accuracy: 0.7585\n",
            "Epoch 17/50\n",
            "625/625 [==============================] - 412s 659ms/step - loss: 0.0917 - accuracy: 0.9689 - val_loss: 1.3641 - val_accuracy: 0.7346\n",
            "Epoch 18/50\n",
            "625/625 [==============================] - 412s 660ms/step - loss: 0.0963 - accuracy: 0.9684 - val_loss: 2.2520 - val_accuracy: 0.7162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f59100094c0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluation\n",
        "\n",
        "ModelLoss, ModelAccuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "print('Model Loss is {}'.format(ModelLoss))\n",
        "print('Model Accuracy is {}'.format(ModelAccuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_4tazo7isM8",
        "outputId": "2945079b-112b-41b8-fd97-6d8b6380671c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 30s 95ms/step - loss: 0.8515 - accuracy: 0.7610\n",
            "Model Loss is 0.8514980673789978\n",
            "Model Accuracy is 0.7609999775886536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Loss : 0.85\n",
        "\n",
        "Model Accuracy : 0.761"
      ],
      "metadata": {
        "id": "hMcXBTbcnmI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "با توجه به اینکه دیتای مورد استفاده دیتای سختی محسوب نمیشود و با توجه به نتایج به دست آمده (دقت 0.76) مشخص است مدل اورفیت شده است. در واقع در صورتی که مدل با تعداد پارامتر بالا مشابه آنچه در این سوال وجود دارد بر روی دیتاستی کوچک ترین شود این اتفاق خواهد افتاد. معمولا گفته میشود به ده برابر تعداد پارامترها داده آموزشی نیاز داریم که در اینجا با وجود اینکه بیش از 23.5 میلیون پارامتر در شبکه وجود دارد تنها 40000 داده‌ی آموزشی داریم. اما در قسمت آ وزن‌هایی که مدل از دیتاستی که پیش از این روی آن ترین شده بود داشت و تنها یک لایه با 10 نرون به آن اضاف شد و این تعداد برای آموزش شبکه کافی بود. در آن حالت دقت حدود %85.7 درصد به دست آمد. اما به نظر میرسد اگر از لایه‌های بیشتری از لایه کاملا متصل نیز استفاده میشد احتمالا به دقت بالاتر از این نیز میرسیدیم"
      ],
      "metadata": {
        "id": "QabiWRIFcKRj"
      }
    }
  ]
}